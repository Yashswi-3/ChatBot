{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yashswi shukla\\Desktop\\Project\\ChatBot\\project\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../scripts')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab26800c74843f8b9c3d7e4e1484cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   4%|4         | 62.9M/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.hf.co/Jean-Baptiste/roberta-large-ner-english/ee8498022f4d5d82c7bcbcff7c017303d09ff0b47b863960724ef34061537df8?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1739911667&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczOTkxMTY2N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9KZWFuLUJhcHRpc3RlL3JvYmVydGEtbGFyZ2UtbmVyLWVuZ2xpc2gvZWU4NDk4MDIyZjRkNWQ4MmM3YmNiY2ZmN2MwMTczMDNkMDlmZjBiNDdiODYzOTYwNzI0ZWYzNDA2MTUzN2RmOD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=S0Wsk%7EPxNBgtZ-pDz7-lFJa5HiGTcmfGvNx8%7Ea-vwthnoBBMSsh0DTTl%7EQx%7EZ7TftUILpkjqiUOTONTxKICOUwVNVfl7DqnNb4x%7ER8oBM5jV4K-urF9X7PUaL4WJ0jw25CeevZxL7sROVjAunOI7EhkA5FN-zvoe6J7navECUMJ%7EO8bEK%7ERNxykem4F9SKc4nPZzv5CuQ89MptntEklHQCqv9LMT9TGuof5Pzefl%7E8aVtNx43EpAY7aaXGPTa9jGH0tI5-lo9E5B252U4m8l6x7tQZWc%7EL2RLo9VfXdOx1dAcXPXwcwJsD7VyQ3MWmyg6waYmwyE3Gw0qNQ7FdbUQw__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455d7c6941964e5282ab873caae7be3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  58%|#####8    | 828M/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15fa7c9a5db4dc3a4d696399938d93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/255 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537701bcfe0f492e9aef59be38476cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "650b185422c64aa99595728eddab2cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf783018b9e496c9b714465e7dd0dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "c:\\ProgramData\\miniconda3\\envs\\pytorch_env\\Lib\\site-packages\\transformers\\pipelines\\token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Entities: [{'entity_group': 'ORG', 'score': np.float32(0.978063), 'word': '\\nEveready Industries India Ltd', 'start': 0, 'end': 30}, {'entity_group': 'ORG', 'score': np.float32(0.9988176), 'word': '.', 'start': 129, 'end': 130}]\n",
      "Final Extracted Financial Data: {'company_name': '.', 'report_date': 'N/A', 'profit_before_tax': '86.25'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Entities: [{'entity_group': 'ORG', 'score': np.float32(0.54578406), 'word': ' ainPeayr', 'start': 60, 'end': 68}, {'entity_group': 'ORG', 'score': np.float32(0.52102005), 'word': 'ange', 'start': 230, 'end': 234}, {'entity_group': 'ORG', 'score': np.float32(0.7240619), 'word': 'IndLitad PhirJoe', 'start': 235, 'end': 251}, {'entity_group': 'ORG', 'score': np.float32(0.6341791), 'word': 'Loiym', 'start': 260, 'end': 265}, {'entity_group': 'ORG', 'score': np.float32(0.58971643), 'word': 'chaPnl', 'start': 273, 'end': 279}, {'entity_group': 'ORG', 'score': np.float32(0.66203415), 'word': 'eDrasl', 'start': 302, 'end': 308}, {'entity_group': 'ORG', 'score': np.float32(0.59948266), 'word': 'Rnas', 'start': 326, 'end': 330}, {'entity_group': 'ORG', 'score': np.float32(0.68980324), 'word': '\\nBandKruarC lo', 'start': 334, 'end': 348}, {'entity_group': 'ORG', 'score': np.float32(0.47121483), 'word': 'olk', 'start': 373, 'end': 376}, {'entity_group': 'ORG', 'score': np.float32(0.66636014), 'word': 'rEMa', 'start': 392, 'end': 396}, {'entity_group': 'ORG', 'score': np.float32(0.57916546), 'word': 'Dea', 'start': 476, 'end': 479}, {'entity_group': 'ORG', 'score': np.float32(0.59752613), 'word': 'ri', 'start': 480, 'end': 482}, {'entity_group': 'ORG', 'score': np.float32(0.67304015), 'word': ' rM sadam', 'start': 484, 'end': 492}, {'entity_group': 'ORG', 'score': np.float32(0.7979318), 'word': 'clousnudreRere', 'start': 502, 'end': 516}, {'entity_group': 'ORG', 'score': np.float32(0.8988928), 'word': 'IL istOibnlgi gaatnidDo', 'start': 536, 'end': 559}, {'entity_group': 'ORG', 'score': np.float32(0.8168354), 'word': ' losure\\nRequireRmeegnutlsa', 'start': 566, 'end': 591}, {'entity_group': 'ORG', 'score': np.float32(0.87409055), 'word': ' aMrede thienlogdn', 'start': 619, 'end': 636}, {'entity_group': 'ORG', 'score': np.float32(0.5622202), 'word': 'uoa', 'start': 661, 'end': 664}, {'entity_group': 'ORG', 'score': np.float32(0.8599995), 'word': 'IL isOtbilnigg aatniDdoi', 'start': 689, 'end': 713}, {'entity_group': 'ORG', 'score': np.float32(0.81129247), 'word': ' lRoesquurier', 'start': 719, 'end': 731}, {'entity_group': 'ORG', 'score': np.float32(0.49728888), 'word': 'ments', 'start': 733, 'end': 738}, {'entity_group': 'ORG', 'score': np.float32(0.85312754), 'word': 'Regula', 'start': 741, 'end': 747}, {'entity_group': 'ORG', 'score': np.float32(0.5524451), 'word': 's', 'start': 759, 'end': 760}, {'entity_group': 'ORG', 'score': np.float32(0.83244383), 'word': ' Is tRienggu lawteiwo', 'start': 766, 'end': 786}, {'entity_group': 'ORG', 'score': np.float32(0.7103225), 'word': ' aorfd\\nDireoc', 'start': 821, 'end': 833}, {'entity_group': 'ORG', 'score': np.float32(0.71959364), 'word': ' hoCero sm paatnthy', 'start': 837, 'end': 855}, {'entity_group': 'ORG', 'score': np.float32(0.87021226), 'word': ' miere thientlgod', 'start': 858, 'end': 874}, {'entity_group': 'ORG', 'score': np.float32(0.9475319), 'word': ' haayis', 'start': 877, 'end': 883}, {'entity_group': 'ORG', 'score': np.float32(0.9625263), 'word': ' tecroanlsiiaad', 'start': 886, 'end': 900}, {'entity_group': 'ORG', 'score': np.float32(0.65866655), 'word': ' ad', 'start': 904, 'end': 906}, {'entity_group': 'ORG', 'score': np.float32(0.5849738), 'word': ' epdr oved\\nth', 'start': 909, 'end': 921}]\n",
      "{\n",
      "    \"company_name\": \" epdr oved\\nth\",\n",
      "    \"report_date\": \"N/A\",\n",
      "    \"net_profit\": \"N/A\",\n",
      "    \"revenue\": \"N/A\",\n",
      "    \"total_assets\": \"N/A\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from scripts.extraction import extract_text_from_pdf\n",
    "from scripts.analysis import extract_financial_data\n",
    "from scripts.formatting import format_to_json\n",
    "\n",
    "# Step 1: Extract text from PDF\n",
    "pdf_path = r\"C:\\Users\\yashswi shukla\\Desktop\\Project\\ChatBot\\project\\data\\raw_pdfs\\1_FinancialResults_05022025142214.pdf\"\n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Step 2: Extract financial data using Hugging Face BERT-based model\n",
    "financial_data = extract_financial_data(extracted_text)\n",
    "\n",
    "# Step 3: Format the extracted data into JSON\n",
    "formatted_json = format_to_json(financial_data)\n",
    "\n",
    "# Step 4: Display the final output\n",
    "print(formatted_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'LOC', 'score': np.float32(0.66101086), 'word': 'Everea', 'start': 0, 'end': 6}, {'entity_group': 'ORG', 'score': np.float32(0.5508759), 'word': '##EG', 'start': 43, 'end': 45}, {'entity_group': 'ORG', 'score': np.float32(0.5592656), 'word': '##C', 'start': 344, 'end': 345}]\n",
      "{'company_name': 'N/A', 'report_date': 'N/A', 'profit': 'N/A'}\n"
     ]
    }
   ],
   "source": [
    "from scripts.extraction import extract_text_from_pdf\n",
    "from scripts.analysis import extract_financial_data\n",
    "\n",
    "pdf_path = r\"C:\\Users\\yashswi shukla\\Desktop\\Project\\ChatBot\\project\\data\\raw_pdfs\\1_FinancialResults_05022025142214.pdf\"\n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "financial_data = extract_financial_data(extracted_text)\n",
    "print(financial_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\miniconda3\\envs\\pytorch_env\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'ORG', 'score': np.float32(0.99964017), 'word': 'ABC Corp', 'start': 0, 'end': 8}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp_ner = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", aggregation_strategy=\"simple\")\n",
    "\n",
    "text = \"ABC Corp reported a profit of $5 million for Q1 2023.\"\n",
    "entities = nlp_ner(text)\n",
    "print(entities)  # Check output format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
